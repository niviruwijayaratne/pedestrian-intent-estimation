{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnames = []\n",
    "ynames = []\n",
    "angle_names = []\n",
    "for i in range(1, 10):\n",
    "    for j in range(i + 1, 10):\n",
    "        xnames.append(\"xd\" + str(i) + str(j))\n",
    "        ynames.append(\"yd\" + str(i) + str(j))\n",
    "        angle_names.append(\"phi1\" + str(i) + str(j))\n",
    "        angle_names.append(\"phi2\" + str(i) + str(j))\n",
    "        \n",
    "triangle_names = []\n",
    "for i in range(1, 10):\n",
    "    for j in range(1, 10):\n",
    "        if j == i:\n",
    "            continue\n",
    "        for k in range(j + 1, 10):\n",
    "            if k == i:\n",
    "                continue\n",
    "            triangle_names.append(\"theta\" + str(i) + str(j) + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "colnames.extend(xnames)\n",
    "colnames.extend(ynames)\n",
    "colnames.extend(angle_names)\n",
    "colnames.extend(triangle_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(1, 15):\n",
    "    names.extend(colnames)\n",
    "names.append(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 15):\n",
    "    for j in range(396*(i-1), 396*i):\n",
    "        names[j] += \"_frame\" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xd12_frame1</th>\n",
       "      <th>xd13_frame1</th>\n",
       "      <th>xd14_frame1</th>\n",
       "      <th>xd15_frame1</th>\n",
       "      <th>xd16_frame1</th>\n",
       "      <th>xd17_frame1</th>\n",
       "      <th>xd18_frame1</th>\n",
       "      <th>xd19_frame1</th>\n",
       "      <th>xd23_frame1</th>\n",
       "      <th>xd24_frame1</th>\n",
       "      <th>...</th>\n",
       "      <th>theta946_frame14</th>\n",
       "      <th>theta947_frame14</th>\n",
       "      <th>theta948_frame14</th>\n",
       "      <th>theta956_frame14</th>\n",
       "      <th>theta957_frame14</th>\n",
       "      <th>theta958_frame14</th>\n",
       "      <th>theta967_frame14</th>\n",
       "      <th>theta968_frame14</th>\n",
       "      <th>theta978_frame14</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.153005</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.109890</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.148352</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.109890</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194595</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.157609</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.103261</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.146739</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.103261</td>\n",
       "      <td>0.201087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.228346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.228346</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.236220</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.228346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.134921</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.134921</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.013570</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2601 rows Ã— 5545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      xd12_frame1  xd13_frame1  xd14_frame1  xd15_frame1  xd16_frame1  \\\n",
       "0        0.213115     0.103825     0.016393     0.153005     0.049180   \n",
       "1        0.219780     0.109890     0.016484     0.148352     0.060440   \n",
       "2        0.194595     0.097297     0.005405     0.151351     0.054054   \n",
       "3        0.195652     0.097826     0.010870     0.157609     0.054348   \n",
       "4        0.206522     0.103261     0.005435     0.146739     0.048913   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2596     0.259843     0.133858     0.031496     0.212598     0.000000   \n",
       "2597     0.265625     0.132812     0.039062     0.218750     0.007812   \n",
       "2598     0.267717     0.133858     0.039370     0.228346     0.015748   \n",
       "2599     0.269841     0.134921     0.055556     0.246032     0.031746   \n",
       "2600     0.256000     0.136000     0.048000     0.232000     0.024000   \n",
       "\n",
       "      xd17_frame1  xd18_frame1  xd19_frame1  xd23_frame1  xd24_frame1  ...  \\\n",
       "0        0.081967     0.065574     0.043716     0.109290     0.196721  ...   \n",
       "1        0.082418     0.060440     0.027473     0.109890     0.203297  ...   \n",
       "2        0.081081     0.021622     0.016216     0.097297     0.189189  ...   \n",
       "3        0.086957     0.021739     0.021739     0.097826     0.184783  ...   \n",
       "4        0.076087     0.070652     0.021739     0.103261     0.201087  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "2596     0.212598     0.031496     0.196850     0.125984     0.228346  ...   \n",
       "2597     0.234375     0.015625     0.210938     0.132812     0.226562  ...   \n",
       "2598     0.236220     0.023622     0.220472     0.133858     0.228346  ...   \n",
       "2599     0.269841     0.031746     0.246032     0.134921     0.214286  ...   \n",
       "2600     0.256000     0.032000     0.248000     0.120000     0.208000  ...   \n",
       "\n",
       "      theta946_frame14  theta947_frame14  theta948_frame14  theta956_frame14  \\\n",
       "0             0.001029          0.001495          0.005838          0.002448   \n",
       "1             0.001272          0.001547          0.006285          0.002648   \n",
       "2             0.001287          0.001546          0.006290          0.002647   \n",
       "3             0.001643          0.001558          0.006524          0.003052   \n",
       "4             0.001599          0.001506          0.006600          0.002981   \n",
       "...                ...               ...               ...               ...   \n",
       "2596          0.002856          0.001998          0.010697          0.005262   \n",
       "2597          0.002482          0.001978          0.010354          0.004875   \n",
       "2598          0.002199          0.001940          0.011453          0.004568   \n",
       "2599          0.001728          0.002071          0.011286          0.004013   \n",
       "2600          0.001055          0.002561          0.011780          0.003412   \n",
       "\n",
       "      theta957_frame14  theta958_frame14  theta967_frame14  theta968_frame14  \\\n",
       "0             0.000076          0.007257          0.002524          0.004809   \n",
       "1             0.000171          0.007661          0.002820          0.005013   \n",
       "2             0.000186          0.007651          0.002833          0.005003   \n",
       "3             0.000149          0.007934          0.003201          0.004882   \n",
       "4             0.000124          0.007982          0.003105          0.005001   \n",
       "...                ...               ...               ...               ...   \n",
       "2596          0.000408          0.013103          0.004854          0.007841   \n",
       "2597          0.000415          0.012747          0.004460          0.007872   \n",
       "2598          0.000430          0.013823          0.004138          0.009255   \n",
       "2599          0.000213          0.013570          0.003800          0.009558   \n",
       "2600          0.000204          0.014138          0.003616          0.010725   \n",
       "\n",
       "      theta978_frame14  label  \n",
       "0             0.007333    0.0  \n",
       "1             0.007833    0.0  \n",
       "2             0.007837    0.0  \n",
       "3             0.008083    0.0  \n",
       "4             0.008106    0.0  \n",
       "...                ...    ...  \n",
       "2596          0.012695    0.0  \n",
       "2597          0.012332    0.0  \n",
       "2598          0.013393    0.0  \n",
       "2599          0.013358    0.0  \n",
       "2600          0.014341    0.0  \n",
       "\n",
       "[2601 rows x 5545 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pose_features_train/final_features.csv\", header=0, names=names) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{408, 409, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 2101, 2102, 2103, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2463, 2464, 2465, 430, 2466, 431, 2467, 432, 2468, 2469, 2470, 2471, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 2234, 2235, 2481, 2482, 447, 2483, 448, 2484, 449, 2485, 450, 2486, 2487, 2488, 2489, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 2329, 2330, 283, 282, 281, 2502, 2503, 468, 2504, 2505, 2506, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 350, 351, 352, 353, 354, 355, 349, 348, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 2517, 2518, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2519, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 2473, 2474, 2475, 2476, 2472, 2478, 2479, 2477, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 2491, 444, 445, 2492, 2493, 443, 2494, 2490, 451, 452, 453, 454, 455, 456, 457, 458, 459, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2507, 469, 470, 471, 472, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2520, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 2597, 2598, 2599, 2600, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 685, 686, 687, 688, 689, 706, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 858, 859, 860, 861, 862, 863, 864, 866, 867, 868, 869, 870, 871, 872, 873, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 953, 954, 955, 956, 957, 958, 959, 960, 963, 964, 965, 966, 967, 968, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1017, 1023, 1024, 1025, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1049, 1050, 1051, 1052, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1161, 1162, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1344, 1345, 1346, 1347, 1348, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1552, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 342, 343, 344, 345, 346, 347, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1890, 1891, 1892, 1893, 1894, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910}\n"
     ]
    }
   ],
   "source": [
    "bads = []\n",
    "for column in names:\n",
    "    if len(df[df[column].isna()]):\n",
    "        bads.append(column)\n",
    "# for i, val in enumerate(df[\"theta123_frame1\"]):\n",
    "#     if val.isna():\n",
    "#         print(i)\n",
    "indices = []\n",
    "for val in bads:\n",
    "    indices.extend(df[val].index[df[val].apply(np.isnan)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta123_frame1\n",
      "theta146_frame1\n",
      "theta213_frame1\n",
      "theta259_frame1\n",
      "theta312_frame1\n",
      "theta368_frame1\n",
      "theta416_frame1\n",
      "theta418_frame1\n",
      "theta468_frame1\n",
      "theta469_frame1\n",
      "theta479_frame1\n",
      "theta567_frame1\n",
      "theta569_frame1\n",
      "theta579_frame1\n",
      "theta614_frame1\n",
      "theta618_frame1\n",
      "theta638_frame1\n",
      "theta648_frame1\n",
      "theta649_frame1\n",
      "theta659_frame1\n",
      "theta749_frame1\n",
      "theta759_frame1\n",
      "theta816_frame1\n",
      "theta836_frame1\n",
      "theta846_frame1\n",
      "theta946_frame1\n",
      "theta947_frame1\n",
      "theta956_frame1\n",
      "theta957_frame1\n",
      "theta123_frame2\n",
      "theta146_frame2\n",
      "theta213_frame2\n",
      "theta259_frame2\n",
      "theta312_frame2\n",
      "theta368_frame2\n",
      "theta416_frame2\n",
      "theta418_frame2\n",
      "theta468_frame2\n",
      "theta469_frame2\n",
      "theta479_frame2\n",
      "theta567_frame2\n",
      "theta569_frame2\n",
      "theta579_frame2\n",
      "theta614_frame2\n",
      "theta618_frame2\n",
      "theta638_frame2\n",
      "theta648_frame2\n",
      "theta649_frame2\n",
      "theta659_frame2\n",
      "theta749_frame2\n",
      "theta759_frame2\n",
      "theta816_frame2\n",
      "theta836_frame2\n",
      "theta846_frame2\n",
      "theta946_frame2\n",
      "theta947_frame2\n",
      "theta956_frame2\n",
      "theta957_frame2\n",
      "theta123_frame3\n",
      "theta146_frame3\n",
      "theta213_frame3\n",
      "theta259_frame3\n",
      "theta312_frame3\n",
      "theta368_frame3\n",
      "theta416_frame3\n",
      "theta418_frame3\n",
      "theta468_frame3\n",
      "theta469_frame3\n",
      "theta479_frame3\n",
      "theta567_frame3\n",
      "theta569_frame3\n",
      "theta578_frame3\n",
      "theta579_frame3\n",
      "theta614_frame3\n",
      "theta618_frame3\n",
      "theta638_frame3\n",
      "theta648_frame3\n",
      "theta649_frame3\n",
      "theta659_frame3\n",
      "theta749_frame3\n",
      "theta758_frame3\n",
      "theta759_frame3\n",
      "theta836_frame3\n",
      "theta846_frame3\n",
      "theta857_frame3\n",
      "theta946_frame3\n",
      "theta947_frame3\n",
      "theta956_frame3\n",
      "theta957_frame3\n",
      "theta123_frame4\n",
      "theta146_frame4\n",
      "theta213_frame4\n",
      "theta312_frame4\n",
      "theta368_frame4\n",
      "theta416_frame4\n",
      "theta418_frame4\n",
      "theta468_frame4\n",
      "theta469_frame4\n",
      "theta479_frame4\n",
      "theta567_frame4\n",
      "theta569_frame4\n",
      "theta578_frame4\n",
      "theta579_frame4\n",
      "theta614_frame4\n",
      "theta618_frame4\n",
      "theta638_frame4\n",
      "theta648_frame4\n",
      "theta649_frame4\n",
      "theta659_frame4\n",
      "theta749_frame4\n",
      "theta758_frame4\n",
      "theta759_frame4\n",
      "theta836_frame4\n",
      "theta846_frame4\n",
      "theta857_frame4\n",
      "theta946_frame4\n",
      "theta947_frame4\n",
      "theta956_frame4\n",
      "theta957_frame4\n",
      "theta123_frame5\n",
      "theta146_frame5\n",
      "theta213_frame5\n",
      "theta312_frame5\n",
      "theta368_frame5\n",
      "theta416_frame5\n",
      "theta418_frame5\n",
      "theta468_frame5\n",
      "theta469_frame5\n",
      "theta479_frame5\n",
      "theta567_frame5\n",
      "theta569_frame5\n",
      "theta578_frame5\n",
      "theta579_frame5\n",
      "theta614_frame5\n",
      "theta618_frame5\n",
      "theta638_frame5\n",
      "theta648_frame5\n",
      "theta649_frame5\n",
      "theta659_frame5\n",
      "theta749_frame5\n",
      "theta758_frame5\n",
      "theta759_frame5\n",
      "theta836_frame5\n",
      "theta846_frame5\n",
      "theta857_frame5\n",
      "theta935_frame5\n",
      "theta946_frame5\n",
      "theta947_frame5\n",
      "theta956_frame5\n",
      "theta957_frame5\n",
      "theta123_frame6\n",
      "theta213_frame6\n",
      "theta312_frame6\n",
      "theta368_frame6\n",
      "theta468_frame6\n",
      "theta469_frame6\n",
      "theta479_frame6\n",
      "theta567_frame6\n",
      "theta569_frame6\n",
      "theta578_frame6\n",
      "theta579_frame6\n",
      "theta638_frame6\n",
      "theta648_frame6\n",
      "theta649_frame6\n",
      "theta659_frame6\n",
      "theta749_frame6\n",
      "theta758_frame6\n",
      "theta759_frame6\n",
      "theta836_frame6\n",
      "theta846_frame6\n",
      "theta857_frame6\n",
      "theta935_frame6\n",
      "theta946_frame6\n",
      "theta947_frame6\n",
      "theta956_frame6\n",
      "theta957_frame6\n",
      "theta123_frame7\n",
      "theta213_frame7\n",
      "theta312_frame7\n",
      "theta368_frame7\n",
      "theta468_frame7\n",
      "theta469_frame7\n",
      "theta479_frame7\n",
      "theta567_frame7\n",
      "theta569_frame7\n",
      "theta578_frame7\n",
      "theta579_frame7\n",
      "theta638_frame7\n",
      "theta648_frame7\n",
      "theta649_frame7\n",
      "theta659_frame7\n",
      "theta749_frame7\n",
      "theta758_frame7\n",
      "theta759_frame7\n",
      "theta836_frame7\n",
      "theta846_frame7\n",
      "theta857_frame7\n",
      "theta935_frame7\n",
      "theta946_frame7\n",
      "theta947_frame7\n",
      "theta956_frame7\n",
      "theta957_frame7\n",
      "theta123_frame8\n",
      "theta213_frame8\n",
      "theta312_frame8\n",
      "theta368_frame8\n",
      "theta468_frame8\n",
      "theta469_frame8\n",
      "theta479_frame8\n",
      "theta569_frame8\n",
      "theta579_frame8\n",
      "theta638_frame8\n",
      "theta648_frame8\n",
      "theta649_frame8\n",
      "theta659_frame8\n",
      "theta749_frame8\n",
      "theta759_frame8\n",
      "theta836_frame8\n",
      "theta846_frame8\n",
      "theta935_frame8\n",
      "theta946_frame8\n",
      "theta947_frame8\n",
      "theta956_frame8\n",
      "theta957_frame8\n",
      "theta123_frame9\n",
      "theta213_frame9\n",
      "theta312_frame9\n",
      "theta368_frame9\n",
      "theta468_frame9\n",
      "theta469_frame9\n",
      "theta479_frame9\n",
      "theta569_frame9\n",
      "theta579_frame9\n",
      "theta638_frame9\n",
      "theta648_frame9\n",
      "theta649_frame9\n",
      "theta659_frame9\n",
      "theta749_frame9\n",
      "theta759_frame9\n",
      "theta836_frame9\n",
      "theta846_frame9\n",
      "theta935_frame9\n",
      "theta946_frame9\n",
      "theta947_frame9\n",
      "theta956_frame9\n",
      "theta957_frame9\n",
      "theta123_frame10\n",
      "theta213_frame10\n",
      "theta312_frame10\n",
      "theta368_frame10\n",
      "theta436_frame10\n",
      "theta468_frame10\n",
      "theta469_frame10\n",
      "theta479_frame10\n",
      "theta569_frame10\n",
      "theta579_frame10\n",
      "theta638_frame10\n",
      "theta648_frame10\n",
      "theta649_frame10\n",
      "theta659_frame10\n",
      "theta749_frame10\n",
      "theta759_frame10\n",
      "theta836_frame10\n",
      "theta846_frame10\n",
      "theta935_frame10\n",
      "theta946_frame10\n",
      "theta947_frame10\n",
      "theta956_frame10\n",
      "theta957_frame10\n",
      "theta123_frame11\n",
      "theta213_frame11\n",
      "theta312_frame11\n",
      "theta368_frame11\n",
      "theta436_frame11\n",
      "theta468_frame11\n",
      "theta469_frame11\n",
      "theta569_frame11\n",
      "theta579_frame11\n",
      "theta638_frame11\n",
      "theta648_frame11\n",
      "theta649_frame11\n",
      "theta659_frame11\n",
      "theta759_frame11\n",
      "theta836_frame11\n",
      "theta846_frame11\n",
      "theta927_frame11\n",
      "theta935_frame11\n",
      "theta946_frame11\n",
      "theta956_frame11\n",
      "theta957_frame11\n",
      "theta123_frame12\n",
      "theta213_frame12\n",
      "theta312_frame12\n",
      "theta368_frame12\n",
      "theta436_frame12\n",
      "theta468_frame12\n",
      "theta469_frame12\n",
      "theta569_frame12\n",
      "theta579_frame12\n",
      "theta638_frame12\n",
      "theta648_frame12\n",
      "theta649_frame12\n",
      "theta659_frame12\n",
      "theta759_frame12\n",
      "theta836_frame12\n",
      "theta846_frame12\n",
      "theta927_frame12\n",
      "theta935_frame12\n",
      "theta946_frame12\n",
      "theta956_frame12\n",
      "theta957_frame12\n",
      "theta123_frame13\n",
      "theta213_frame13\n",
      "theta312_frame13\n",
      "theta368_frame13\n",
      "theta436_frame13\n",
      "theta468_frame13\n",
      "theta469_frame13\n",
      "theta569_frame13\n",
      "theta579_frame13\n",
      "theta638_frame13\n",
      "theta648_frame13\n",
      "theta649_frame13\n",
      "theta659_frame13\n",
      "theta759_frame13\n",
      "theta836_frame13\n",
      "theta846_frame13\n",
      "theta927_frame13\n",
      "theta935_frame13\n",
      "theta946_frame13\n",
      "theta956_frame13\n",
      "theta957_frame13\n",
      "theta123_frame14\n",
      "theta213_frame14\n",
      "theta312_frame14\n",
      "theta368_frame14\n",
      "theta436_frame14\n",
      "theta468_frame14\n",
      "theta469_frame14\n",
      "theta569_frame14\n",
      "theta579_frame14\n",
      "theta618_frame14\n",
      "theta638_frame14\n",
      "theta648_frame14\n",
      "theta649_frame14\n",
      "theta659_frame14\n",
      "theta759_frame14\n",
      "theta836_frame14\n",
      "theta846_frame14\n",
      "theta927_frame14\n",
      "theta935_frame14\n",
      "theta946_frame14\n",
      "theta956_frame14\n",
      "theta957_frame14\n"
     ]
    }
   ],
   "source": [
    "for col in bads:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"theta123_frame1\"].isna().iloc[788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna()\n",
    "# for column in names:\n",
    "#     if len(df2[df2[column].isna()]):\n",
    "#         bads.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite = []\n",
    "for i, val in enumerate(X_train):\n",
    "    for j, v in enumerate(val):\n",
    "        if not np.isfinite(v):\n",
    "            finite.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(finite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df2.iloc[:, :-1].values.astype(np.float32)\n",
    "Y = df2.iloc[:, -1].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a4ed38d9fea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=400, random_state=0, max_depth = 15)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
